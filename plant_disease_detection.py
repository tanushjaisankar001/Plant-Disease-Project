# -*- coding: utf-8 -*-
"""Plant-Disease-Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VkEsQHtmcT-k8Ee8lPuljbGs7JUYbtIM
"""

from google.colab import drive
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

drive.mount('/content/drive')

zip_file_path = "/content/drive/My Drive/archive.zip"

!unzip -q "{zip_file_path}" -d "/content/plant_dataset"
print("✅ Data unzipped successfully to Colab's local disk.")

IMAGE_SIZE = 256
BATCH_SIZE = 16
CHANNELS = 3
EPOCHS = 15
dataset_path = "/content/plant_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train"

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

val_batches = tf.data.experimental.cardinality(val_ds)
test_ds = val_ds.take(val_batches // 2)
val_ds = val_ds.skip(val_batches // 2)

class_names = train_ds.class_names
print("✅ Data successfully loaded and split.")
print(f"Training batches: {len(train_ds)}, Validation batches: {len(val_ds)}, Test batches: {len(test_ds)}")

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache(filename='./train_cache').shuffle(500).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache(filename='./val_cache').prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache(filename='./test_cache').prefetch(buffer_size=AUTOTUNE)
print("✅ Performance optimizations applied (caching to disk).")

plt.figure(figsize=(12, 12))
for image_batch, label_batch in train_ds.take(1):
    for i in range(12):
        ax = plt.subplot(3, 4, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[label_batch[i]])
        plt.axis("off")
plt.show()

IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)

base_model = tf.keras.applications.MobileNetV2(
    input_shape=IMG_SHAPE,
    include_top=False,
    weights='imagenet'
)

base_model.trainable = False

print("✅ Base model loaded and frozen.")

from tensorflow.keras import layers, models

n_classes = len(class_names)

model = models.Sequential([
    base_model,

    layers.GlobalAveragePooling2D(),

    layers.Dense(64, activation='relu'),

    layers.Dropout(0.2),

    layers.Dense(n_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

model.summary()